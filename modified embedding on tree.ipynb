{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zqtan/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import itertools\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "from gensim.corpora import Dictionary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the `text8` corpus. It is one very long succession of words. There are no sentence boundaries or punctuation marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organiz'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./text8') as f:\n",
    "    s = f.read()\n",
    "s[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the corpus into sentences, it is convenient to use the `Text8Corpus` function from `gensim`. We choose to work with $1000$ words per sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anarchism',\n",
       " 'originated',\n",
       " 'as',\n",
       " 'a',\n",
       " 'term',\n",
       " 'of',\n",
       " 'abuse',\n",
       " 'first',\n",
       " 'used',\n",
       " 'against',\n",
       " 'early',\n",
       " 'working',\n",
       " 'class',\n",
       " 'radicals',\n",
       " 'including',\n",
       " 'the',\n",
       " 'diggers',\n",
       " 'of',\n",
       " 'the',\n",
       " 'english',\n",
       " 'revolution',\n",
       " 'and',\n",
       " 'the',\n",
       " 'sans',\n",
       " 'culottes',\n",
       " 'of',\n",
       " 'the',\n",
       " 'french',\n",
       " 'revolution',\n",
       " 'whilst',\n",
       " 'the',\n",
       " 'term',\n",
       " 'is',\n",
       " 'still',\n",
       " 'used',\n",
       " 'in',\n",
       " 'a',\n",
       " 'pejorative',\n",
       " 'way',\n",
       " 'to',\n",
       " 'describe',\n",
       " 'any',\n",
       " 'act',\n",
       " 'that',\n",
       " 'used',\n",
       " 'violent',\n",
       " 'means',\n",
       " 'to',\n",
       " 'destroy',\n",
       " 'the',\n",
       " 'organization',\n",
       " 'of',\n",
       " 'society',\n",
       " 'it',\n",
       " 'has',\n",
       " 'also',\n",
       " 'been',\n",
       " 'taken',\n",
       " 'up',\n",
       " 'as',\n",
       " 'a',\n",
       " 'positive',\n",
       " 'label',\n",
       " 'by',\n",
       " 'self',\n",
       " 'defined',\n",
       " 'anarchists',\n",
       " 'the',\n",
       " 'word',\n",
       " 'anarchism',\n",
       " 'is',\n",
       " 'derived',\n",
       " 'from',\n",
       " 'the',\n",
       " 'greek',\n",
       " 'without',\n",
       " 'archons',\n",
       " 'ruler',\n",
       " 'chief',\n",
       " 'king',\n",
       " 'anarchism',\n",
       " 'as',\n",
       " 'a',\n",
       " 'political',\n",
       " 'philosophy',\n",
       " 'is',\n",
       " 'the',\n",
       " 'belief',\n",
       " 'that',\n",
       " 'rulers',\n",
       " 'are',\n",
       " 'unnecessary',\n",
       " 'and',\n",
       " 'should',\n",
       " 'be',\n",
       " 'abolished',\n",
       " 'although',\n",
       " 'there',\n",
       " 'are',\n",
       " 'differing',\n",
       " 'interpretations',\n",
       " 'of',\n",
       " 'what',\n",
       " 'this',\n",
       " 'means',\n",
       " 'anarchism',\n",
       " 'also',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'related',\n",
       " 'social',\n",
       " 'movements',\n",
       " 'that',\n",
       " 'advocate',\n",
       " 'the',\n",
       " 'elimination',\n",
       " 'of',\n",
       " 'authoritarian',\n",
       " 'institutions',\n",
       " 'particularly',\n",
       " 'the',\n",
       " 'state',\n",
       " 'the',\n",
       " 'word',\n",
       " 'anarchy',\n",
       " 'as',\n",
       " 'most',\n",
       " 'anarchists',\n",
       " 'use',\n",
       " 'it',\n",
       " 'does',\n",
       " 'not',\n",
       " 'imply',\n",
       " 'chaos',\n",
       " 'nihilism',\n",
       " 'or',\n",
       " 'anomie',\n",
       " 'but',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'harmonious',\n",
       " 'anti',\n",
       " 'authoritarian',\n",
       " 'society',\n",
       " 'in',\n",
       " 'place',\n",
       " 'of',\n",
       " 'what',\n",
       " 'are',\n",
       " 'regarded',\n",
       " 'as',\n",
       " 'authoritarian',\n",
       " 'political',\n",
       " 'structures',\n",
       " 'and',\n",
       " 'coercive',\n",
       " 'economic',\n",
       " 'institutions',\n",
       " 'anarchists',\n",
       " 'advocate',\n",
       " 'social',\n",
       " 'relations',\n",
       " 'based',\n",
       " 'upon',\n",
       " 'voluntary',\n",
       " 'association',\n",
       " 'of',\n",
       " 'autonomous',\n",
       " 'individuals',\n",
       " 'mutual',\n",
       " 'aid',\n",
       " 'and',\n",
       " 'self',\n",
       " 'governance',\n",
       " 'while',\n",
       " 'anarchism',\n",
       " 'is',\n",
       " 'most',\n",
       " 'easily',\n",
       " 'defined',\n",
       " 'by',\n",
       " 'what',\n",
       " 'it',\n",
       " 'is',\n",
       " 'against',\n",
       " 'anarchists',\n",
       " 'also',\n",
       " 'offer',\n",
       " 'positive',\n",
       " 'visions',\n",
       " 'of',\n",
       " 'what',\n",
       " 'they',\n",
       " 'believe',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'truly',\n",
       " 'free',\n",
       " 'society',\n",
       " 'however',\n",
       " 'ideas',\n",
       " 'about',\n",
       " 'how',\n",
       " 'an',\n",
       " 'anarchist',\n",
       " 'society',\n",
       " 'might',\n",
       " 'work',\n",
       " 'vary',\n",
       " 'considerably',\n",
       " 'especially',\n",
       " 'with',\n",
       " 'respect',\n",
       " 'to',\n",
       " 'economics',\n",
       " 'there',\n",
       " 'is',\n",
       " 'also',\n",
       " 'disagreement',\n",
       " 'about',\n",
       " 'how',\n",
       " 'a',\n",
       " 'free',\n",
       " 'society',\n",
       " 'might',\n",
       " 'be',\n",
       " 'brought',\n",
       " 'about',\n",
       " 'origins',\n",
       " 'and',\n",
       " 'predecessors',\n",
       " 'kropotkin',\n",
       " 'and',\n",
       " 'others',\n",
       " 'argue',\n",
       " 'that',\n",
       " 'before',\n",
       " 'recorded',\n",
       " 'history',\n",
       " 'human',\n",
       " 'society',\n",
       " 'was',\n",
       " 'organized',\n",
       " 'on',\n",
       " 'anarchist',\n",
       " 'principles',\n",
       " 'most',\n",
       " 'anthropologists',\n",
       " 'follow',\n",
       " 'kropotkin',\n",
       " 'and',\n",
       " 'engels',\n",
       " 'in',\n",
       " 'believing',\n",
       " 'that',\n",
       " 'hunter',\n",
       " 'gatherer',\n",
       " 'bands',\n",
       " 'were',\n",
       " 'egalitarian',\n",
       " 'and',\n",
       " 'lacked',\n",
       " 'division',\n",
       " 'of',\n",
       " 'labour',\n",
       " 'accumulated',\n",
       " 'wealth',\n",
       " 'or',\n",
       " 'decreed',\n",
       " 'law',\n",
       " 'and',\n",
       " 'had',\n",
       " 'equal',\n",
       " 'access',\n",
       " 'to',\n",
       " 'resources',\n",
       " 'william',\n",
       " 'godwin',\n",
       " 'anarchists',\n",
       " 'including',\n",
       " 'the',\n",
       " 'the',\n",
       " 'anarchy',\n",
       " 'organisation',\n",
       " 'and',\n",
       " 'rothbard',\n",
       " 'find',\n",
       " 'anarchist',\n",
       " 'attitudes',\n",
       " 'in',\n",
       " 'taoism',\n",
       " 'from',\n",
       " 'ancient',\n",
       " 'china',\n",
       " 'kropotkin',\n",
       " 'found',\n",
       " 'similar',\n",
       " 'ideas',\n",
       " 'in',\n",
       " 'stoic',\n",
       " 'zeno',\n",
       " 'of',\n",
       " 'citium',\n",
       " 'according',\n",
       " 'to',\n",
       " 'kropotkin',\n",
       " 'zeno',\n",
       " 'repudiated',\n",
       " 'the',\n",
       " 'omnipotence',\n",
       " 'of',\n",
       " 'the',\n",
       " 'state',\n",
       " 'its',\n",
       " 'intervention',\n",
       " 'and',\n",
       " 'regimentation',\n",
       " 'and',\n",
       " 'proclaimed',\n",
       " 'the',\n",
       " 'sovereignty',\n",
       " 'of',\n",
       " 'the',\n",
       " 'moral',\n",
       " 'law',\n",
       " 'of',\n",
       " 'the',\n",
       " 'individual',\n",
       " 'the',\n",
       " 'anabaptists',\n",
       " 'of',\n",
       " 'one',\n",
       " 'six',\n",
       " 'th',\n",
       " 'century',\n",
       " 'europe',\n",
       " 'are',\n",
       " 'sometimes',\n",
       " 'considered',\n",
       " 'to',\n",
       " 'be',\n",
       " 'religious',\n",
       " 'forerunners',\n",
       " 'of',\n",
       " 'modern',\n",
       " 'anarchism',\n",
       " 'bertrand',\n",
       " 'russell',\n",
       " 'in',\n",
       " 'his',\n",
       " 'history',\n",
       " 'of',\n",
       " 'western',\n",
       " 'philosophy',\n",
       " 'writes',\n",
       " 'that',\n",
       " 'the',\n",
       " 'anabaptists',\n",
       " 'repudiated',\n",
       " 'all',\n",
       " 'law',\n",
       " 'since',\n",
       " 'they',\n",
       " 'held',\n",
       " 'that',\n",
       " 'the',\n",
       " 'good',\n",
       " 'man',\n",
       " 'will',\n",
       " 'be',\n",
       " 'guided',\n",
       " 'at',\n",
       " 'every',\n",
       " 'moment',\n",
       " 'by',\n",
       " 'the',\n",
       " 'holy',\n",
       " 'spirit',\n",
       " 'from',\n",
       " 'this',\n",
       " 'premise',\n",
       " 'they',\n",
       " 'arrive',\n",
       " 'at',\n",
       " 'communism',\n",
       " 'the',\n",
       " 'diggers',\n",
       " 'or',\n",
       " 'true',\n",
       " 'levellers',\n",
       " 'were',\n",
       " 'an',\n",
       " 'early',\n",
       " 'communistic',\n",
       " 'movement',\n",
       " 'during',\n",
       " 'the',\n",
       " 'time',\n",
       " 'of',\n",
       " 'the',\n",
       " 'english',\n",
       " 'civil',\n",
       " 'war',\n",
       " 'and',\n",
       " 'are',\n",
       " 'considered',\n",
       " 'by',\n",
       " 'some',\n",
       " 'as',\n",
       " 'forerunners',\n",
       " 'of',\n",
       " 'modern',\n",
       " 'anarchism',\n",
       " 'in',\n",
       " 'the',\n",
       " 'modern',\n",
       " 'era',\n",
       " 'the',\n",
       " 'first',\n",
       " 'to',\n",
       " 'use',\n",
       " 'the',\n",
       " 'term',\n",
       " 'to',\n",
       " 'mean',\n",
       " 'something',\n",
       " 'other',\n",
       " 'than',\n",
       " 'chaos',\n",
       " 'was',\n",
       " 'louis',\n",
       " 'armand',\n",
       " 'baron',\n",
       " 'de',\n",
       " 'lahontan',\n",
       " 'in',\n",
       " 'his',\n",
       " 'nouveaux',\n",
       " 'voyages',\n",
       " 'dans',\n",
       " 'l',\n",
       " 'am',\n",
       " 'rique',\n",
       " 'septentrionale',\n",
       " 'one',\n",
       " 'seven',\n",
       " 'zero',\n",
       " 'three',\n",
       " 'where',\n",
       " 'he',\n",
       " 'described',\n",
       " 'the',\n",
       " 'indigenous',\n",
       " 'american',\n",
       " 'society',\n",
       " 'which',\n",
       " 'had',\n",
       " 'no',\n",
       " 'state',\n",
       " 'laws',\n",
       " 'prisons',\n",
       " 'priests',\n",
       " 'or',\n",
       " 'private',\n",
       " 'property',\n",
       " 'as',\n",
       " 'being',\n",
       " 'in',\n",
       " 'anarchy',\n",
       " 'russell',\n",
       " 'means',\n",
       " 'a',\n",
       " 'libertarian',\n",
       " 'and',\n",
       " 'leader',\n",
       " 'in',\n",
       " 'the',\n",
       " 'american',\n",
       " 'indian',\n",
       " 'movement',\n",
       " 'has',\n",
       " 'repeatedly',\n",
       " 'stated',\n",
       " 'that',\n",
       " 'he',\n",
       " 'is',\n",
       " 'an',\n",
       " 'anarchist',\n",
       " 'and',\n",
       " 'so',\n",
       " 'are',\n",
       " 'all',\n",
       " 'his',\n",
       " 'ancestors',\n",
       " 'in',\n",
       " 'one',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'three',\n",
       " 'in',\n",
       " 'the',\n",
       " 'thick',\n",
       " 'of',\n",
       " 'the',\n",
       " 'french',\n",
       " 'revolution',\n",
       " 'william',\n",
       " 'godwin',\n",
       " 'published',\n",
       " 'an',\n",
       " 'enquiry',\n",
       " 'concerning',\n",
       " 'political',\n",
       " 'justice',\n",
       " 'although',\n",
       " 'godwin',\n",
       " 'did',\n",
       " 'not',\n",
       " 'use',\n",
       " 'the',\n",
       " 'word',\n",
       " 'anarchism',\n",
       " 'many',\n",
       " 'later',\n",
       " 'anarchists',\n",
       " 'have',\n",
       " 'regarded',\n",
       " 'this',\n",
       " 'book',\n",
       " 'as',\n",
       " 'the',\n",
       " 'first',\n",
       " 'major',\n",
       " 'anarchist',\n",
       " 'text',\n",
       " 'and',\n",
       " 'godwin',\n",
       " 'as',\n",
       " 'the',\n",
       " 'founder',\n",
       " 'of',\n",
       " 'philosophical',\n",
       " 'anarchism',\n",
       " 'but',\n",
       " 'at',\n",
       " 'this',\n",
       " 'point',\n",
       " 'no',\n",
       " 'anarchist',\n",
       " 'movement',\n",
       " 'yet',\n",
       " 'existed',\n",
       " 'and',\n",
       " 'the',\n",
       " 'term',\n",
       " 'anarchiste',\n",
       " 'was',\n",
       " 'known',\n",
       " 'mainly',\n",
       " 'as',\n",
       " 'an',\n",
       " 'insult',\n",
       " 'hurled',\n",
       " 'by',\n",
       " 'the',\n",
       " 'bourgeois',\n",
       " 'girondins',\n",
       " 'at',\n",
       " 'more',\n",
       " 'radical',\n",
       " 'elements',\n",
       " 'in',\n",
       " 'the',\n",
       " 'french',\n",
       " 'revolution',\n",
       " 'the',\n",
       " 'first',\n",
       " 'self',\n",
       " 'labelled',\n",
       " 'anarchist',\n",
       " 'pierre',\n",
       " 'joseph',\n",
       " 'proudhon',\n",
       " 'it',\n",
       " 'is',\n",
       " 'commonly',\n",
       " 'held',\n",
       " 'that',\n",
       " 'it',\n",
       " 'wasn',\n",
       " 't',\n",
       " 'until',\n",
       " 'pierre',\n",
       " 'joseph',\n",
       " 'proudhon',\n",
       " 'published',\n",
       " 'what',\n",
       " 'is',\n",
       " 'property',\n",
       " 'in',\n",
       " 'one',\n",
       " 'eight',\n",
       " 'four',\n",
       " 'zero',\n",
       " 'that',\n",
       " 'the',\n",
       " 'term',\n",
       " 'anarchist',\n",
       " 'was',\n",
       " 'adopted',\n",
       " 'as',\n",
       " 'a',\n",
       " 'self',\n",
       " 'description',\n",
       " 'it',\n",
       " 'is',\n",
       " 'for',\n",
       " 'this',\n",
       " 'reason',\n",
       " 'that',\n",
       " 'some',\n",
       " 'claim',\n",
       " 'proudhon',\n",
       " 'as',\n",
       " 'the',\n",
       " 'founder',\n",
       " 'of',\n",
       " 'modern',\n",
       " 'anarchist',\n",
       " 'theory',\n",
       " 'in',\n",
       " 'what',\n",
       " 'is',\n",
       " 'property',\n",
       " 'proudhon',\n",
       " 'answers',\n",
       " 'with',\n",
       " 'the',\n",
       " 'famous',\n",
       " 'accusation',\n",
       " 'property',\n",
       " 'is',\n",
       " 'theft',\n",
       " 'in',\n",
       " 'this',\n",
       " 'work',\n",
       " 'he',\n",
       " 'opposed',\n",
       " 'the',\n",
       " 'institution',\n",
       " 'of',\n",
       " 'decreed',\n",
       " 'property',\n",
       " 'propri',\n",
       " 't',\n",
       " 'where',\n",
       " 'owners',\n",
       " 'have',\n",
       " 'complete',\n",
       " 'rights',\n",
       " 'to',\n",
       " 'use',\n",
       " 'and',\n",
       " 'abuse',\n",
       " 'their',\n",
       " 'property',\n",
       " 'as',\n",
       " 'they',\n",
       " 'wish',\n",
       " 'such',\n",
       " 'as',\n",
       " 'exploiting',\n",
       " 'workers',\n",
       " 'for',\n",
       " 'profit',\n",
       " 'in',\n",
       " 'its',\n",
       " 'place',\n",
       " 'proudhon',\n",
       " 'supported',\n",
       " 'what',\n",
       " 'he',\n",
       " 'called',\n",
       " 'possession',\n",
       " 'individuals',\n",
       " 'can',\n",
       " 'have',\n",
       " 'limited',\n",
       " 'rights',\n",
       " 'to',\n",
       " 'use',\n",
       " 'resources',\n",
       " 'capital',\n",
       " 'and',\n",
       " 'goods',\n",
       " 'in',\n",
       " 'accordance',\n",
       " 'with',\n",
       " 'principles',\n",
       " 'of',\n",
       " 'equality',\n",
       " 'and',\n",
       " 'justice',\n",
       " 'proudhon',\n",
       " 's',\n",
       " 'vision',\n",
       " 'of',\n",
       " 'anarchy',\n",
       " 'which',\n",
       " 'he',\n",
       " 'called',\n",
       " 'mutualism',\n",
       " 'mutuellisme',\n",
       " 'involved',\n",
       " 'an',\n",
       " 'exchange',\n",
       " 'economy',\n",
       " 'where',\n",
       " 'individuals',\n",
       " 'and',\n",
       " 'groups',\n",
       " 'could',\n",
       " 'trade',\n",
       " 'the',\n",
       " 'products',\n",
       " 'of',\n",
       " 'their',\n",
       " 'labor',\n",
       " 'using',\n",
       " 'labor',\n",
       " 'notes',\n",
       " 'which',\n",
       " 'represented',\n",
       " 'the',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'working',\n",
       " 'time',\n",
       " 'involved',\n",
       " 'in',\n",
       " 'production',\n",
       " 'this',\n",
       " 'would',\n",
       " 'ensure',\n",
       " 'that',\n",
       " 'no',\n",
       " 'one',\n",
       " 'would',\n",
       " 'profit',\n",
       " 'from',\n",
       " 'the',\n",
       " 'labor',\n",
       " 'of',\n",
       " 'others',\n",
       " 'workers',\n",
       " 'could',\n",
       " 'freely',\n",
       " 'join',\n",
       " 'together',\n",
       " 'in',\n",
       " 'co',\n",
       " 'operative',\n",
       " 'workshops',\n",
       " 'an',\n",
       " 'interest',\n",
       " 'free',\n",
       " 'bank',\n",
       " 'would',\n",
       " 'be',\n",
       " 'set',\n",
       " 'up',\n",
       " 'to',\n",
       " 'provide',\n",
       " 'everyone',\n",
       " 'with',\n",
       " 'access',\n",
       " 'to',\n",
       " 'the',\n",
       " 'means',\n",
       " 'of',\n",
       " 'production',\n",
       " 'proudhon',\n",
       " 's',\n",
       " 'ideas',\n",
       " 'were',\n",
       " 'influential',\n",
       " 'within',\n",
       " 'french',\n",
       " 'working',\n",
       " 'class',\n",
       " 'movements',\n",
       " 'and',\n",
       " 'his',\n",
       " 'followers',\n",
       " 'were',\n",
       " 'active',\n",
       " 'in',\n",
       " 'the',\n",
       " 'revolution',\n",
       " 'of',\n",
       " 'one',\n",
       " 'eight',\n",
       " 'four',\n",
       " 'eight',\n",
       " 'in',\n",
       " 'france',\n",
       " 'proudhon',\n",
       " 's',\n",
       " 'philosophy',\n",
       " 'of',\n",
       " 'property',\n",
       " 'is',\n",
       " 'complex',\n",
       " 'it',\n",
       " 'was',\n",
       " 'developed',\n",
       " 'in',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'works',\n",
       " 'over',\n",
       " 'his',\n",
       " 'lifetime',\n",
       " 'and',\n",
       " 'there',\n",
       " 'are',\n",
       " 'differing',\n",
       " 'interpretations',\n",
       " 'of',\n",
       " 'some',\n",
       " 'of',\n",
       " 'his',\n",
       " 'ideas',\n",
       " 'for',\n",
       " 'more',\n",
       " 'detailed',\n",
       " 'discussion',\n",
       " 'see',\n",
       " 'here',\n",
       " 'max',\n",
       " 'stirner',\n",
       " 's',\n",
       " 'egoism',\n",
       " 'in',\n",
       " 'his',\n",
       " 'the',\n",
       " 'ego',\n",
       " 'and',\n",
       " 'its',\n",
       " 'own',\n",
       " 'stirner',\n",
       " 'argued',\n",
       " 'that',\n",
       " 'most',\n",
       " 'commonly',\n",
       " 'accepted',\n",
       " 'social',\n",
       " 'institutions',\n",
       " 'including',\n",
       " 'the',\n",
       " 'notion',\n",
       " 'of',\n",
       " 'state',\n",
       " 'property',\n",
       " 'as',\n",
       " 'a',\n",
       " 'right',\n",
       " 'natural',\n",
       " 'rights',\n",
       " 'in',\n",
       " 'general',\n",
       " 'and',\n",
       " 'the',\n",
       " 'very',\n",
       " 'notion',\n",
       " 'of',\n",
       " 'society',\n",
       " 'were',\n",
       " 'mere',\n",
       " 'illusions',\n",
       " 'or',\n",
       " 'ghosts',\n",
       " 'in',\n",
       " 'the',\n",
       " 'mind',\n",
       " 'saying',\n",
       " 'of',\n",
       " 'society',\n",
       " 'that',\n",
       " 'the',\n",
       " 'individuals',\n",
       " 'are',\n",
       " 'its',\n",
       " 'reality',\n",
       " 'he',\n",
       " 'advocated',\n",
       " 'egoism',\n",
       " 'and',\n",
       " 'a',\n",
       " 'form',\n",
       " 'of',\n",
       " 'amoralism',\n",
       " 'in',\n",
       " 'which',\n",
       " 'individuals',\n",
       " 'would',\n",
       " 'unite',\n",
       " 'in',\n",
       " 'associations',\n",
       " 'of',\n",
       " 'egoists',\n",
       " 'only',\n",
       " 'when',\n",
       " 'it',\n",
       " 'was',\n",
       " 'in',\n",
       " 'their',\n",
       " 'self',\n",
       " 'interest',\n",
       " 'to',\n",
       " 'do',\n",
       " 'so',\n",
       " 'for',\n",
       " 'him',\n",
       " 'property',\n",
       " 'simply',\n",
       " 'comes',\n",
       " 'about',\n",
       " 'through',\n",
       " 'might',\n",
       " 'whoever',\n",
       " 'knows',\n",
       " 'how',\n",
       " 'to',\n",
       " 'take',\n",
       " 'to',\n",
       " 'defend',\n",
       " 'the',\n",
       " 'thing',\n",
       " 'to',\n",
       " 'him',\n",
       " 'belongs',\n",
       " 'property',\n",
       " 'and',\n",
       " 'what',\n",
       " 'i',\n",
       " 'have',\n",
       " 'in',\n",
       " 'my',\n",
       " 'power',\n",
       " 'that',\n",
       " 'is',\n",
       " 'my',\n",
       " 'own',\n",
       " 'so',\n",
       " 'long',\n",
       " 'as',\n",
       " 'i',\n",
       " 'assert',\n",
       " 'myself',\n",
       " 'as',\n",
       " 'holder',\n",
       " 'i',\n",
       " 'am',\n",
       " 'the',\n",
       " 'proprietor',\n",
       " 'of',\n",
       " 'the',\n",
       " 'thing',\n",
       " 'stirner',\n",
       " 'never',\n",
       " 'called',\n",
       " 'himself',\n",
       " 'an',\n",
       " 'anarchist',\n",
       " 'he',\n",
       " 'accepted',\n",
       " 'only',\n",
       " 'the',\n",
       " 'label',\n",
       " 'egoist',\n",
       " 'nevertheless',\n",
       " 'his',\n",
       " 'ideas',\n",
       " 'were',\n",
       " 'influential',\n",
       " 'on',\n",
       " 'many',\n",
       " 'individualistically',\n",
       " 'inclined',\n",
       " 'anarchists',\n",
       " 'although',\n",
       " 'interpretations',\n",
       " 'of',\n",
       " 'his',\n",
       " 'thought',\n",
       " 'are',\n",
       " 'diverse']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = Text8Corpus('./text8', max_sentence_length=1000)\n",
    "sentences = list(itertools.islice(Text8Corpus('./text8', max_sentence_length=1000), None))\n",
    "sentences[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As done in the paper we only keep the $8000$ most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = Dictionary(corpus)\n",
    "dct.filter_extremes(no_below=1, no_above=0.5, keep_n=8000)  #筛选词频\n",
    "#dct.doc2idx('anarchism')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We establish a correspondence between words and unique numeric identifiers. This makes it easy to build one-hot vectors afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents2idx = [dct.doc2idx(sentence) for sentence in sentences]         #编号是按照字母序对单词排的（可以通过打印看）\n",
    "sents2idx = [[idx for idx in sent if idx != -1] for sent in sents2idx]\n",
    "sents_8k = [[dct[idx] for idx in sent] for sent in sents2idx]\n",
    "dct2 = Dictionary(sents_8k)\n",
    "sents2idx = [dct.doc2idx(sentence) for sentence in sents_8k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the first sentence of the corpus looks like (first 10 words only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[193, 261, 1, 11, 83, 303, 53, 133, 90, 233]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents2idx[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pre-compute all the context windows for all the sentences in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts_all = []\n",
    "for sent in sents2idx:\n",
    "    contexts_sent = []\n",
    "    for i in range(len(sent)):\n",
    "        context = []\n",
    "        for j in range(max(i-2,0), min(i+2, len(sent))):\n",
    "            context.append(sent[j])\n",
    "        contexts_sent.append((sent[i], context))\n",
    "    contexts_all.append(contexts_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the contexts for the first 10 words of the first sentence look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(193, [193, 261]),\n",
       " (261, [193, 261, 1]),\n",
       " (1, [193, 261, 1, 11]),\n",
       " (11, [261, 1, 11, 83]),\n",
       " (83, [1, 11, 83, 303]),\n",
       " (303, [11, 83, 303, 53]),\n",
       " (53, [83, 303, 53, 133]),\n",
       " (133, [303, 53, 133, 90]),\n",
       " (90, [53, 133, 90, 233]),\n",
       " (233, [133, 90, 233, 111])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts_all[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a custom dataloader that creates the batches during training. Each batch is made of `bsize` sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(bsize):\n",
    "    idx_shuffle = np.random.permutation(len(sents2idx))\n",
    "    for i in range(0, len(sents2idx), bsize):\n",
    "        batch = []\n",
    "        for idx in idx_shuffle[i: min(i+bsize, len(sents2idx))]:\n",
    "            contexts = contexts_all[idx]\n",
    "            sent = sents2idx[idx]\n",
    "            contexts_enriched = []\n",
    "            for (token, context) in contexts:\n",
    "                negatives = []\n",
    "                for _ in range(len(context)):\n",
    "                    negative = random.choice(sent)  # Negative sampling happens here\n",
    "                    while negative in context:\n",
    "                        negative = random.choice(sent)\n",
    "                    negatives.append(negative)\n",
    "                contexts_enriched.append((token, context, negatives))\n",
    "            batch.append(contexts_enriched)\n",
    "        yield batch\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code for the Sinkhorn iterations. We chose to implement vanilla iterations, but it would have been preferable to work in log-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mydevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#mydevice=\"cpu\"\n",
    "        \n",
    "#alpha = 2.0\n",
    "               \n",
    "n_inner = 10\n",
    "\n",
    "def smoothabs(x, alpha):\n",
    "    \"\"\"\n",
    "    differential absolute function using smooth max.\n",
    "\n",
    "    Caution.\n",
    "    if x is large (over 100), this returns nan.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.tensor\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    result : torch.tensor\n",
    "\n",
    "    \"\"\"\n",
    "    return  (x*torch.exp(alpha*x) - x*torch.exp(-alpha*x)) / (2.0 + torch.exp(alpha*x) + torch.exp(-alpha*x)).to(mydevice)\n",
    " \n",
    "\n",
    "\n",
    "class Tree_dis(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_inner, n_leaf, device='cpu', max_d=None, alpha=2.0):\n",
    "        super(Tree_dis, self).__init__()\n",
    "        self.n_inner = n_inner # number of inner nodes which contained root.\n",
    "        self.n_leaf = n_leaf # number of leaf nodes. (e.g., number of words)\n",
    "        self.n_node = self.n_leaf + self.n_inner # number of all nodes.\n",
    "        self.device = device\n",
    "        self.alpha = alpha\n",
    "               \n",
    "        self.param = torch.nn.Parameter(torch.randn(self.n_inner, self.n_leaf, device=self.device)) # D2\n",
    "\n",
    "        # initialize parameters\n",
    "        nn.init.normal_(self.param, 0.0, 0.1)\n",
    "        \n",
    "        self.A = self.gen_A()\n",
    "        self.inv_A = self.calc_inv_A() # (I - D1)^{-1}\n",
    "\n",
    "    def gen_A(self):\n",
    "        \"\"\"\n",
    "        Initialize D1, which is an adjacency matrix of a tree consisting of internal nodes and return I - D1.\n",
    "        Assume D1 is the perfect 5-ary tree.\n",
    "        \"\"\"\n",
    "        \n",
    "        A = torch.zeros(self.n_inner, self.n_inner-1)\n",
    "        for i in range(1, int(self.n_inner/5)):\n",
    "            A[i-1, 5*(i-1):5*i] = 1.0\n",
    "        A[int(self.n_inner/5)-1, 5*(int(self.n_inner/5)-1):] = 1.0\n",
    "        A = A.to(self.device)\n",
    "        return torch.eye(self.n_inner, device=self.device) - torch.cat([torch.zeros(self.n_inner, 1, device=self.device), A], dim=1).to(self.device)\n",
    "\n",
    "    \n",
    "    def calc_inv_A(self):\n",
    "        \"\"\"\n",
    "        return (I - D1)^{-1}.\n",
    "        \"\"\"\n",
    "        return self.A.inverse()\n",
    "\n",
    "    \n",
    "    def calc_ppar(self):\n",
    "        \"\"\"\n",
    "        return upper two blocks of D_par.\n",
    "        \"\"\"\n",
    "        \n",
    "        exp_param = F.softmax(self.param, dim=0)\n",
    "        return torch.cat([torch.eye(self.n_inner, device=self.device) - self.A, exp_param], dim=1)\n",
    "\n",
    "    \n",
    "    def calc_psub(self, block_D=None):\n",
    "        \"\"\"\n",
    "        Retuens\n",
    "        ----------\n",
    "        X : torch.tensor (shape is (self.n_inner, self.n_leaf))\n",
    "            X[i][j] is P_sub (v_j+self.n_inner | v_i).\n",
    "        \"\"\"\n",
    "        \n",
    "        B = F.softmax(self.param, dim=0).to(mydevice)\n",
    "        X = torch.mm(self.inv_A, B).to(mydevice)\n",
    "        return X.to(mydevice)\n",
    "\n",
    "    \n",
    "    def calc_distance(self, mass1, mass2, block_psub=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        mass1 : torch.tensor (shape is (self.n_leaf))\n",
    "            normalized bag-of-words.\n",
    "        mass2 : torch.tensor (shape is (self.n_leaf))\n",
    "            normalized bag-of-words\n",
    "        block_psub : torch.tensor (shape is (self.n_inner, self.n_leaf))\n",
    "            retuen value of self.calc_plock_psub().\n",
    "        \"\"\"\n",
    "        if block_psub is None:\n",
    "            block_psub = self.calc_psub()\n",
    "        return (smoothabs(torch.mv(block_psub, mass1 - mass2), alpha=self.alpha).sum() + smoothabs(mass1 - mass2, alpha=self.alpha).sum()).to(mydevice)\n",
    "\n",
    "    def forward(self, x , y):\n",
    "        return self.calc_distance(x,y).to(mydevice)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the architecture for the neural network. The inputs are one-hot vectors of size $8000$ and the output is a $2M$ vector that will be reshaped as a cloud of $M$ points in $\\mathbb R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_leaf = 4  #M为leaf数\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(8000, 64)\n",
    "        self.fc2 = nn.Linear(64, n_leaf)\n",
    "        #self.param=torch.nn.Parameter(torch.randn(n_inner, n_leaf ,device=mydevice))   #D2\n",
    "        #self.param=torch.randn(n_inner, n_leaf )\n",
    "        self.soft= nn.Softmax()\n",
    "        #self.X= calc_psub(self.param)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.soft(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.to(mydevice)\n",
    "tree_loss = Tree_dis(n_inner,n_leaf,mydevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([obj for obj in net.parameters()]+[obj for obj in tree_loss.parameters()] ,lr=10**-4)\n",
    "#itertools.chain(net.parameters(),tree_loss.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(n):\n",
    "    vect = torch.zeros(8000)\n",
    "    vect[n] = 1.0\n",
    "    return vect.to(mydevice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is our training loop. Please disregard the output of this cell. The network we trained was saved as `net.pth`. The training was done with a batch size of $1$ and we interrupted it after $4$ hours (the first epoch was far from over since the loop went through only $\\sim 3000$ sentences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1\n",
    "bsize = 1\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(loader(bsize), 0):   #每个batch做一次参数优化（即一次正向反向）\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = torch.zeros(1).to(mydevice)\n",
    "        #print(\"starting batch\")\n",
    "        for sent in batch:\n",
    "            for (token, context, negatives) in sent:\n",
    "                token_emb = net(one_hot(token)) \n",
    "                for positive in context:\n",
    "                    positive_emb = net(one_hot(positive)) \n",
    "                    \n",
    "                    loss += tree_loss(token_emb,positive_emb) **2\n",
    "                for negative in negatives:\n",
    "                    negative_emb =  net(one_hot(negative)) \n",
    "                    loss += net.relu(m-tree_loss(token_emb,negative_emb)) **2\n",
    "            #print(\"finished sentence\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 40==39:    \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, './net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load('./net.pth')\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power tensor([0.1975, 0.2534, 0.2074, 0.3417], device='cuda:0')\n",
      "earth tensor([0.1900, 0.2195, 0.2025, 0.3880], device='cuda:0')\n",
      "mathematics tensor([0.1956, 0.3287, 0.2009, 0.2748], device='cuda:0')\n",
      "preservation tensor([0.1919, 0.3673, 0.1953, 0.2456], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-d89db8fd0b42>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.soft(x)\n",
      "<ipython-input-18-f81320553feb>:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print('power',net.soft(test1))\n",
      "<ipython-input-18-f81320553feb>:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print('earth',net.soft(test2))\n",
      "<ipython-input-18-f81320553feb>:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print('mathematics',net.soft(test3))\n",
      "<ipython-input-18-f81320553feb>:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print('preservation',net.soft(test4))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test1 = net(one_hot(dct2.token2id['power']))\n",
    "    test2 = net(one_hot(dct2.token2id['earth']))\n",
    "    test3 = net(one_hot(dct2.token2id['mathematics']))\n",
    "    test4 = net(one_hot(dct2.token2id['preservation']))\n",
    "print('power',net.soft(test1))\n",
    "print('earth',net.soft(test2))\n",
    "print('mathematics',net.soft(test3))\n",
    "print('preservation',net.soft(test4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "football tensor([0.1916, 0.3751, 0.1948, 0.2385], device='cuda:0')\n",
      "basketball tensor([0.1948, 0.2866, 0.2026, 0.3160], device='cuda:0')\n",
      "soccer tensor([0.1948, 0.2944, 0.2022, 0.3085], device='cuda:0')\n",
      "rugby tensor([0.1942, 0.3363, 0.1992, 0.2702], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-d89db8fd0b42>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.soft(x)\n",
      "<ipython-input-19-172cbd652841>:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print('football',net.soft(test1))\n",
      "<ipython-input-19-172cbd652841>:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print(\"basketball\",net.soft(test2))\n",
      "<ipython-input-19-172cbd652841>:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print('soccer',net.soft(test3))\n",
      "<ipython-input-19-172cbd652841>:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print('rugby',net.soft(test4))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test1 = net(one_hot(dct2.token2id['football']))\n",
    "    test2 = net(one_hot(dct2.token2id[\"basketball\"]))\n",
    "    test3 = net(one_hot(dct2.token2id['soccer']))\n",
    "    test4 = net(one_hot(dct2.token2id['rugby']))\n",
    "print('football',net.soft(test1))\n",
    "print(\"basketball\",net.soft(test2))\n",
    "print('soccer',net.soft(test3))\n",
    "print('rugby',net.soft(test4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1048, -0.2223,  0.1390, -0.0582],\n",
      "        [ 0.1683,  0.1879, -0.3083, -0.1569],\n",
      "        [-0.1339, -0.3543,  0.2439,  0.1495],\n",
      "        [ 0.1014, -0.1270,  0.2683,  0.3706],\n",
      "        [ 0.0021, -0.1617,  0.2419,  0.1417],\n",
      "        [-0.0322, -0.2477,  0.2202,  0.0320],\n",
      "        [-0.2538, -0.1566,  0.0391,  0.2050],\n",
      "        [-0.1332,  0.3028, -0.2484, -0.0427],\n",
      "        [ 0.0675,  0.3515, -0.1485, -0.2209],\n",
      "        [ 0.1382,  0.3066, -0.2694, -0.3281]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for obj in tree_loss.parameters():\n",
    "    print(obj)           #没softmax前的，但也可以大小直接看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sents2idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2c3124e402fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msents2idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sents2idx' is not defined"
     ]
    }
   ],
   "source": [
    "len(sents2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
